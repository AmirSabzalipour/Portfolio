---
layout: page
title: About
permalink: /about/
position: 1
feature-img: "assets/img/pexels/travel2.JPG"
---

## About Me  

 <div class="row">
        <div class="col-lg-8">
          <div class="image-container d-flex">
            <div class="image-item">
              <img
                src="m5.jpg"
                alt="Portrait of Mary Shelley"
                class="mary-photo img-fluid"
              />
              <p class="image-caption">Mary Shelley, 1797-1851</p>
            </div>
            <div class="image-item">
              <img
                src="m5.jpg"
                alt="Portrait of Percy Shelley"
                class="percy-photo img-fluid"
              />
              <p class="image-caption">Percy Shelley, 1819-1889</p>
            </div>
          </div>
        </div>
      </div>













<img src="https://raw.githubusercontent.com/AmirSabzalipour/Portfolio/assets/img/amir.jpg" 
     alt="Amir Sabzalipour" 
     style="width: 100px; border-radius: 50%; display: block; margin: 0 auto;">

<p style="line-height: 1.8;">
I am a machine learning researcher specializing in large language models (LLMs) and natural language processing (NLP), with a <strong>Ph.D. in Physics</strong> and <strong>postdoctoral research experience</strong>.  
My work is heavily focused on <strong>training and fine-tuning LLMs</strong>, as well as <strong>prompt engineering</strong>, utilizing <strong>high-performance computing (HPC) clusters</strong> to optimize large-scale AI models.  
</p>  

<p style="line-height: 1.8;">
I have extensive experience in <strong>scalable model training and deployment</strong>, leveraging tools such as <strong>Ray, Docker, and vLLM</strong> to efficiently manage distributed computing workloads for LLM development.  
My expertise spans <strong>transformer architectures, deep learning, and text generation</strong>, enabling me to design and implement <strong>custom training pipelines, hyperparameter tuning, and model optimization strategies</strong> for enhanced language understanding and contextual reasoning.  
</p>  

<p style="line-height: 1.8;">
Combining a rigorous <strong>scientific mindset</strong> with a passion for <strong>AI-driven innovation</strong>, I continuously push the boundaries of <strong>LLM performance, interpretability, and real-world deployment</strong>, ensuring that state-of-the-art models are both powerful and practical.  
</p>

