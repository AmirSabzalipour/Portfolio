---
layout: post
title: ""
tags: [Katex, Mermaid, Markdown]
date: 2025-03-26 12:00:00 +0000
categories: Demo
---
About Me

I am a machine learning researcher specializing in large language models (LLMs) and natural language processing (NLP), with a Ph.D. in Physics and postdoctoral research experience. My work is heavily focused on training and fine-tuning LLMs, as well as prompt engineering, utilizing high-performance computing (HPC) clusters to optimize large-scale AI models.

I have extensive experience in scalable model training and deployment, leveraging tools such as Ray, Docker, and vLLM to efficiently manage distributed computing workloads for LLM development. My expertise spans transformer architectures, deep learning, and text generation, enabling me to design and implement custom training pipelines, hyperparameter tuning, and model optimization strategies for enhanced language understanding and contextual reasoning.

Combining a rigorous scientific mindset with a passion for AI-driven innovation, I continuously push the boundaries of LLM performance, interpretability, and real-world deployment, ensuring that state-of-the-art models are both powerful and practical.
 

